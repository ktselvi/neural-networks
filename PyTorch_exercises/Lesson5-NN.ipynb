{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training neural network to classify handwritten digits exercise\n",
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9912320/9912422 [01:06<00:00, 100899.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      "32768it [00:00, 36166.05it/s]                           \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:00<00:28, 56694.42it/s]\u001b[A\n",
      "  2%|▏         | 32768/1648877 [00:01<00:27, 58387.63it/s]\u001b[A\n",
      "  3%|▎         | 57344/1648877 [00:01<00:23, 66355.90it/s]\u001b[A\n",
      "  4%|▍         | 73728/1648877 [00:01<00:24, 64766.54it/s]\u001b[A\n",
      "  6%|▌         | 98304/1648877 [00:01<00:21, 71814.59it/s]\u001b[A\n",
      "  7%|▋         | 122880/1648877 [00:02<00:19, 77617.68it/s]\u001b[A\n",
      "  9%|▉         | 147456/1648877 [00:02<00:18, 82570.78it/s]\u001b[A\n",
      " 10%|█         | 172032/1648877 [00:02<00:17, 84790.15it/s]\u001b[A\n",
      " 12%|█▏        | 204800/1648877 [00:02<00:15, 93399.54it/s]\u001b[A\n",
      " 14%|█▍        | 229376/1648877 [00:03<00:19, 72808.17it/s]\u001b[A\n",
      " 16%|█▋        | 270336/1648877 [00:03<00:15, 87479.64it/s]\u001b[A\n",
      " 17%|█▋        | 286720/1648877 [00:03<00:17, 79792.21it/s]\u001b[A\n",
      " 19%|█▉        | 311296/1648877 [00:04<00:15, 84595.89it/s]\u001b[A\n",
      " 20%|██        | 335872/1648877 [00:04<00:14, 88185.09it/s]\u001b[A\n",
      " 22%|██▏       | 360448/1648877 [00:04<00:13, 96550.96it/s]\u001b[A\n",
      " 23%|██▎       | 385024/1648877 [00:04<00:11, 106192.04it/s]\u001b[A\n",
      " 24%|██▍       | 401408/1648877 [00:04<00:11, 107336.70it/s]\u001b[A\n",
      " 25%|██▌       | 417792/1648877 [00:05<00:10, 116938.60it/s]\u001b[A\n",
      " 26%|██▋       | 434176/1648877 [00:05<00:10, 117429.36it/s]\u001b[A\n",
      " 27%|██▋       | 450560/1648877 [00:05<00:12, 96844.78it/s] \u001b[A\n",
      " 29%|██▉       | 475136/1648877 [00:05<00:14, 83655.64it/s]\u001b[A\n",
      " 31%|███       | 507904/1648877 [00:05<00:10, 104851.40it/s]\u001b[A\n",
      " 32%|███▏      | 524288/1648877 [00:06<00:10, 109709.64it/s]\u001b[A\n",
      " 33%|███▎      | 540672/1648877 [00:06<00:09, 118277.00it/s]\u001b[A\n",
      " 34%|███▍      | 557056/1648877 [00:06<00:11, 95057.61it/s] \u001b[A\n",
      " 35%|███▍      | 573440/1648877 [00:06<00:13, 80566.20it/s]\u001b[A\n",
      " 36%|███▋      | 598016/1648877 [00:07<00:12, 85336.76it/s]\u001b[A\n",
      " 38%|███▊      | 622592/1648877 [00:07<00:10, 101167.64it/s]\u001b[A\n",
      " 39%|███▉      | 638976/1648877 [00:07<00:09, 110849.92it/s]\u001b[A\n",
      " 40%|███▉      | 655360/1648877 [00:07<00:09, 109691.79it/s]\u001b[A\n",
      " 41%|████      | 671744/1648877 [00:07<00:08, 120720.56it/s]\u001b[A\n",
      " 42%|████▏     | 688128/1648877 [00:07<00:10, 95613.22it/s] \u001b[A\n",
      " 43%|████▎     | 712704/1648877 [00:07<00:08, 110136.87it/s]\u001b[A\n",
      " 44%|████▍     | 729088/1648877 [00:08<00:07, 116831.03it/s]\u001b[A\n",
      " 45%|████▌     | 745472/1648877 [00:08<00:07, 118061.93it/s]\u001b[A\n",
      " 46%|████▌     | 761856/1648877 [00:08<00:07, 120096.47it/s]\u001b[A\n",
      " 47%|████▋     | 778240/1648877 [00:08<00:09, 96664.24it/s] \u001b[A\n",
      " 49%|████▊     | 802816/1648877 [00:08<00:07, 113006.55it/s]\u001b[A\n",
      " 50%|████▉     | 819200/1648877 [00:08<00:07, 114674.37it/s]\u001b[A\n",
      " 51%|█████     | 835584/1648877 [00:08<00:06, 118253.46it/s]\u001b[A\n",
      " 52%|█████▏    | 851968/1648877 [00:09<00:06, 119509.04it/s]\u001b[A\n",
      " 53%|█████▎    | 868352/1648877 [00:09<00:08, 96072.66it/s] \u001b[A\n",
      " 54%|█████▍    | 892928/1648877 [00:09<00:06, 111718.47it/s]\u001b[A\n",
      " 55%|█████▌    | 909312/1648877 [00:09<00:06, 119509.21it/s]\u001b[A\n",
      " 56%|█████▌    | 925696/1648877 [00:09<00:05, 120726.55it/s]\u001b[A\n",
      " 57%|█████▋    | 942080/1648877 [00:09<00:05, 126065.05it/s]\u001b[A\n",
      " 58%|█████▊    | 958464/1648877 [00:10<00:08, 77943.45it/s] \u001b[A\n",
      " 60%|██████    | 991232/1648877 [00:10<00:06, 100707.83it/s]\u001b[A\n",
      " 62%|██████▏   | 1015808/1648877 [00:10<00:06, 100334.53it/s]\u001b[A\n",
      " 63%|██████▎   | 1032192/1648877 [00:10<00:07, 88017.05it/s] \u001b[A\n",
      " 64%|██████▍   | 1056768/1648877 [00:11<00:06, 90516.51it/s]\u001b[A\n",
      " 66%|██████▌   | 1089536/1648877 [00:11<00:05, 99868.12it/s]\u001b[A\n",
      " 68%|██████▊   | 1114112/1648877 [00:11<00:04, 117918.29it/s]\u001b[A\n",
      " 69%|██████▊   | 1130496/1648877 [00:11<00:04, 116241.60it/s]\u001b[A\n",
      " 70%|██████▉   | 1146880/1648877 [00:11<00:03, 126672.69it/s]\u001b[A\n",
      " 71%|███████   | 1163264/1648877 [00:11<00:03, 122223.83it/s]\u001b[A\n",
      " 72%|███████▏  | 1179648/1648877 [00:11<00:03, 131511.74it/s]\u001b[A\n",
      " 73%|███████▎  | 1196032/1648877 [00:12<00:03, 125123.54it/s]\u001b[A\n",
      " 74%|███████▎  | 1212416/1648877 [00:12<00:03, 132563.09it/s]\u001b[A\n",
      "9920512it [01:20, 100899.19it/s]                             \u001b[A\n",
      " 76%|███████▌  | 1245184/1648877 [00:12<00:03, 133155.93it/s]\u001b[A\n",
      " 77%|███████▋  | 1261568/1648877 [00:12<00:03, 126075.62it/s]\u001b[A\n",
      " 78%|███████▊  | 1277952/1648877 [00:12<00:02, 130239.65it/s]\u001b[A\n",
      " 78%|███████▊  | 1294336/1648877 [00:12<00:02, 128703.13it/s]\u001b[A\n",
      " 79%|███████▉  | 1310720/1648877 [00:13<00:03, 105663.68it/s]\u001b[A\n",
      " 81%|████████▏ | 1343488/1648877 [00:13<00:02, 112101.83it/s]\u001b[A\n",
      " 83%|████████▎ | 1376256/1648877 [00:13<00:02, 116978.05it/s]\u001b[A\n",
      " 85%|████████▍ | 1400832/1648877 [00:13<00:01, 132962.29it/s]\u001b[A\n",
      " 86%|████████▌ | 1417216/1648877 [00:13<00:01, 124780.24it/s]\u001b[A\n",
      " 87%|████████▋ | 1441792/1648877 [00:14<00:01, 114920.62it/s]\u001b[A\n",
      " 89%|████████▉ | 1466368/1648877 [00:14<00:01, 130315.30it/s]\u001b[A\n",
      " 90%|████████▉ | 1482752/1648877 [00:14<00:01, 131025.17it/s]\u001b[A\n",
      " 91%|█████████▏| 1507328/1648877 [00:14<00:01, 125377.73it/s]\u001b[A\n",
      " 93%|█████████▎| 1531904/1648877 [00:14<00:00, 139588.31it/s]\u001b[A\n",
      " 94%|█████████▍| 1548288/1648877 [00:14<00:00, 127692.26it/s]\u001b[A\n",
      " 96%|█████████▌| 1581056/1648877 [00:15<00:00, 134388.51it/s]\u001b[A\n",
      " 97%|█████████▋| 1605632/1648877 [00:15<00:00, 147954.64it/s]\u001b[A\n",
      " 98%|█████████▊| 1622016/1648877 [00:15<00:00, 131430.08it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8192it [00:00, 15824.72it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/thankaselv.kumaresan/.pytorch/MNIST_data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1654784it [00:32, 131430.08it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "# Downloading MNIST data set using torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\" Sigmoid activation function \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random weights and bias\n",
    "torch.manual_seed(5)\n",
    "n_input = 784    # Number of input units-28x28\n",
    "n_hidden = 256    # Number of hidden units \n",
    "n_output = 10\n",
    "\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))\n",
    "\n",
    "# Flattening images - Understood this logic from https://deeplizard.com/learn/video/fCVuiW9AFzY\n",
    "def flatten(t):\n",
    "    t = t.reshape(t.shape[0], -1)\n",
    "    t = t.squeeze()\n",
    "    return t\n",
    "\n",
    "images_flat_input = flatten(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_l1 = activation(torch.mm(images_flat_input, W1)+B1)\n",
    "output_l2 = torch.mm(output_l1, W2)+B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining softmax function\n",
    "def softmax(x):\n",
    "    sum = torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "    return torch.exp(x)/sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "probabilities = softmax(output_l2)\n",
    "\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building neural network using NN Module\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
